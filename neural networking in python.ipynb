{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "918bf03e",
   "metadata": {},
   "source": [
    "### Understanding neural networking in simple steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be27aa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143e2263",
   "metadata": {},
   "source": [
    "#### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c7e773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset for\n",
    "data = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1079a3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#viewing data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c88236",
   "metadata": {},
   "source": [
    "##### The objective is to predict based on diagnostic measurements whether a patient has diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "952759c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "data['Outcome'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4824fc41",
   "metadata": {},
   "source": [
    "### Preparing Data For Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6560b77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into input(X) and output(y) variables\n",
    "predictors = data.iloc[:,0:8]\n",
    "response = data.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "350e2ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 8) (614,)\n",
      "(154, 8) (154,)\n"
     ]
    }
   ],
   "source": [
    "# create training and testing vars\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, response, test_size=0.2)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ca039c",
   "metadata": {},
   "source": [
    "### Training the neural network model\n",
    "### There are two ways to build keras models: sequential and functional\n",
    "### The sequential API allows you to create models layer by layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "217bc03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model - layer by layer\n",
    "kerasmodel = Sequential() #initializing model - Dense for fully connected layer\n",
    "kerasmodel.add(Dense(12, input_dim=8, activation='relu')) # First hidden layer\n",
    "kerasmodel.add(Dense(8, activation='relu')) #Relu to avoid vanishing/exploading gradient problem \n",
    "kerasmodel.add(Dense(1, activation='sigmoid')) #since output is binary so \"sigmoid\"- #Outpul layer\n",
    "\n",
    "#please note Weight and bias initialization are done by keras default methods using \"glorot_uniform\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37aeb5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling model\n",
    "kerasmodel.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2354b3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "62/62 [==============================] - 22s 2ms/step - loss: 7.9657 - accuracy: 0.3937\n",
      "Epoch 2/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 2.0320 - accuracy: 0.4877\n",
      "Epoch 3/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.9734 - accuracy: 0.5881\n",
      "Epoch 4/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 1.2103 - accuracy: 0.5898\n",
      "Epoch 5/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 1.2008 - accuracy: 0.6295\n",
      "Epoch 6/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.8233 - accuracy: 0.5654\n",
      "Epoch 7/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.8946 - accuracy: 0.6117\n",
      "Epoch 8/150\n",
      "62/62 [==============================] - 0s 955us/step - loss: 0.7803 - accuracy: 0.6290\n",
      "Epoch 9/150\n",
      "62/62 [==============================] - 0s 926us/step - loss: 0.7813 - accuracy: 0.5964\n",
      "Epoch 10/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.7606 - accuracy: 0.6122\n",
      "Epoch 11/150\n",
      "62/62 [==============================] - 0s 930us/step - loss: 0.7212 - accuracy: 0.6352\n",
      "Epoch 12/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6769 - accuracy: 0.6605\n",
      "Epoch 13/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.7659 - accuracy: 0.6518\n",
      "Epoch 14/150\n",
      "62/62 [==============================] - 0s 996us/step - loss: 0.6265 - accuracy: 0.6831\n",
      "Epoch 15/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6161 - accuracy: 0.6981\n",
      "Epoch 16/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5901 - accuracy: 0.7189\n",
      "Epoch 17/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6241 - accuracy: 0.7064\n",
      "Epoch 18/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5950 - accuracy: 0.7000\n",
      "Epoch 19/150\n",
      "62/62 [==============================] - 0s 986us/step - loss: 0.6152 - accuracy: 0.7109\n",
      "Epoch 20/150\n",
      "62/62 [==============================] - 0s 962us/step - loss: 0.6403 - accuracy: 0.6726\n",
      "Epoch 21/150\n",
      "62/62 [==============================] - 0s 954us/step - loss: 0.6211 - accuracy: 0.6955\n",
      "Epoch 22/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6355 - accuracy: 0.6897\n",
      "Epoch 23/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6237 - accuracy: 0.6835\n",
      "Epoch 24/150\n",
      "62/62 [==============================] - 0s 903us/step - loss: 0.5655 - accuracy: 0.7316\n",
      "Epoch 25/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5987 - accuracy: 0.6929\n",
      "Epoch 26/150\n",
      "62/62 [==============================] - 0s 997us/step - loss: 0.6492 - accuracy: 0.6727\n",
      "Epoch 27/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5997 - accuracy: 0.7143\n",
      "Epoch 28/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5735 - accuracy: 0.7187: 0s - loss: 0.5688 - accuracy: 0.72\n",
      "Epoch 29/150\n",
      "62/62 [==============================] - 0s 949us/step - loss: 0.6062 - accuracy: 0.7022\n",
      "Epoch 30/150\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.6080 - accuracy: 0.71 - 0s 1ms/step - loss: 0.6106 - accuracy: 0.7147\n",
      "Epoch 31/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6096 - accuracy: 0.6706\n",
      "Epoch 32/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5802 - accuracy: 0.7093\n",
      "Epoch 33/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5955 - accuracy: 0.7047\n",
      "Epoch 34/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5929 - accuracy: 0.7265\n",
      "Epoch 35/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5973 - accuracy: 0.7072\n",
      "Epoch 36/150\n",
      "62/62 [==============================] - 0s 747us/step - loss: 0.5992 - accuracy: 0.6940\n",
      "Epoch 37/150\n",
      "62/62 [==============================] - 0s 782us/step - loss: 0.5645 - accuracy: 0.7291\n",
      "Epoch 38/150\n",
      "62/62 [==============================] - 0s 791us/step - loss: 0.6209 - accuracy: 0.6552\n",
      "Epoch 39/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5846 - accuracy: 0.7112\n",
      "Epoch 40/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5745 - accuracy: 0.7120\n",
      "Epoch 41/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5901 - accuracy: 0.7120\n",
      "Epoch 42/150\n",
      "62/62 [==============================] - 0s 964us/step - loss: 0.6139 - accuracy: 0.6999\n",
      "Epoch 43/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5836 - accuracy: 0.7155\n",
      "Epoch 44/150\n",
      "62/62 [==============================] - 0s 948us/step - loss: 0.5956 - accuracy: 0.7093\n",
      "Epoch 45/150\n",
      "62/62 [==============================] - 0s 932us/step - loss: 0.6135 - accuracy: 0.7169\n",
      "Epoch 46/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5793 - accuracy: 0.7220\n",
      "Epoch 47/150\n",
      "62/62 [==============================] - 0s 965us/step - loss: 0.6044 - accuracy: 0.6914\n",
      "Epoch 48/150\n",
      "62/62 [==============================] - 0s 965us/step - loss: 0.5750 - accuracy: 0.7262\n",
      "Epoch 49/150\n",
      "62/62 [==============================] - 0s 932us/step - loss: 0.5544 - accuracy: 0.7547\n",
      "Epoch 50/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5976 - accuracy: 0.6975\n",
      "Epoch 51/150\n",
      "62/62 [==============================] - 0s 981us/step - loss: 0.5879 - accuracy: 0.6846\n",
      "Epoch 52/150\n",
      "62/62 [==============================] - 0s 867us/step - loss: 0.5534 - accuracy: 0.7436\n",
      "Epoch 53/150\n",
      "62/62 [==============================] - 0s 932us/step - loss: 0.5618 - accuracy: 0.7273\n",
      "Epoch 54/150\n",
      "62/62 [==============================] - 0s 867us/step - loss: 0.6000 - accuracy: 0.7231\n",
      "Epoch 55/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5683 - accuracy: 0.7034\n",
      "Epoch 56/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5428 - accuracy: 0.7547\n",
      "Epoch 57/150\n",
      "62/62 [==============================] - 0s 965us/step - loss: 0.5687 - accuracy: 0.7109\n",
      "Epoch 58/150\n",
      "62/62 [==============================] - 0s 948us/step - loss: 0.5614 - accuracy: 0.7308\n",
      "Epoch 59/150\n",
      "62/62 [==============================] - 0s 949us/step - loss: 0.5596 - accuracy: 0.7171\n",
      "Epoch 60/150\n",
      "62/62 [==============================] - 0s 966us/step - loss: 0.6608 - accuracy: 0.7038\n",
      "Epoch 61/150\n",
      "62/62 [==============================] - 0s 955us/step - loss: 0.5785 - accuracy: 0.7078\n",
      "Epoch 62/150\n",
      "62/62 [==============================] - 0s 967us/step - loss: 0.5671 - accuracy: 0.7134\n",
      "Epoch 63/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5802 - accuracy: 0.7088\n",
      "Epoch 64/150\n",
      "62/62 [==============================] - 0s 982us/step - loss: 0.5244 - accuracy: 0.7747\n",
      "Epoch 65/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5584 - accuracy: 0.7245\n",
      "Epoch 66/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5129 - accuracy: 0.7626\n",
      "Epoch 67/150\n",
      "62/62 [==============================] - 0s 963us/step - loss: 0.5646 - accuracy: 0.7153\n",
      "Epoch 68/150\n",
      "62/62 [==============================] - 0s 969us/step - loss: 0.5564 - accuracy: 0.73580s - loss: 0.5552 - accuracy: 0.73\n",
      "Epoch 69/150\n",
      "62/62 [==============================] - 0s 974us/step - loss: 0.5753 - accuracy: 0.7091\n",
      "Epoch 70/150\n",
      "62/62 [==============================] - 0s 972us/step - loss: 0.5637 - accuracy: 0.7007\n",
      "Epoch 71/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5484 - accuracy: 0.7479\n",
      "Epoch 72/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5344 - accuracy: 0.7448\n",
      "Epoch 73/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5117 - accuracy: 0.7689\n",
      "Epoch 74/150\n",
      "62/62 [==============================] - 0s 980us/step - loss: 0.5403 - accuracy: 0.7338\n",
      "Epoch 75/150\n",
      "62/62 [==============================] - 0s 930us/step - loss: 0.5598 - accuracy: 0.7221\n",
      "Epoch 76/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5424 - accuracy: 0.7337\n",
      "Epoch 77/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5898 - accuracy: 0.6916\n",
      "Epoch 78/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5190 - accuracy: 0.7646\n",
      "Epoch 79/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5294 - accuracy: 0.7454\n",
      "Epoch 80/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5550 - accuracy: 0.7281\n",
      "Epoch 81/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5342 - accuracy: 0.7519\n",
      "Epoch 82/150\n",
      "62/62 [==============================] - 0s 993us/step - loss: 0.5222 - accuracy: 0.7552\n",
      "Epoch 83/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5435 - accuracy: 0.7391\n",
      "Epoch 84/150\n",
      "62/62 [==============================] - 0s 998us/step - loss: 0.5535 - accuracy: 0.7271\n",
      "Epoch 85/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5548 - accuracy: 0.7207\n",
      "Epoch 86/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5602 - accuracy: 0.7249\n",
      "Epoch 87/150\n",
      "62/62 [==============================] - 0s 946us/step - loss: 0.5418 - accuracy: 0.7502\n",
      "Epoch 88/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5339 - accuracy: 0.7415\n",
      "Epoch 89/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5231 - accuracy: 0.7714\n",
      "Epoch 90/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.6146 - accuracy: 0.7426\n",
      "Epoch 91/150\n",
      "62/62 [==============================] - 0s 999us/step - loss: 0.5556 - accuracy: 0.7463\n",
      "Epoch 92/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5255 - accuracy: 0.7502\n",
      "Epoch 93/150\n",
      "62/62 [==============================] - 0s 982us/step - loss: 0.5047 - accuracy: 0.7606\n",
      "Epoch 94/150\n",
      "62/62 [==============================] - 0s 932us/step - loss: 0.5043 - accuracy: 0.7580\n",
      "Epoch 95/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5271 - accuracy: 0.7458\n",
      "Epoch 96/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5520 - accuracy: 0.7097\n",
      "Epoch 97/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5205 - accuracy: 0.7473\n",
      "Epoch 98/150\n",
      "62/62 [==============================] - 0s 996us/step - loss: 0.5142 - accuracy: 0.7803\n",
      "Epoch 99/150\n",
      "62/62 [==============================] - 0s 945us/step - loss: 0.4922 - accuracy: 0.7603\n",
      "Epoch 100/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5115 - accuracy: 0.7444\n",
      "Epoch 101/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5499 - accuracy: 0.7380\n",
      "Epoch 102/150\n",
      "62/62 [==============================] - 0s 971us/step - loss: 0.5387 - accuracy: 0.7480\n",
      "Epoch 103/150\n",
      "62/62 [==============================] - 0s 945us/step - loss: 0.5310 - accuracy: 0.7334\n",
      "Epoch 104/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5376 - accuracy: 0.7457\n",
      "Epoch 105/150\n",
      "62/62 [==============================] - 0s 999us/step - loss: 0.5508 - accuracy: 0.7439\n",
      "Epoch 106/150\n",
      "62/62 [==============================] - 0s 934us/step - loss: 0.5442 - accuracy: 0.7299\n",
      "Epoch 107/150\n",
      "62/62 [==============================] - 0s 929us/step - loss: 0.5470 - accuracy: 0.7388\n",
      "Epoch 108/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5224 - accuracy: 0.7674\n",
      "Epoch 109/150\n",
      "62/62 [==============================] - 0s 977us/step - loss: 0.5293 - accuracy: 0.7362\n",
      "Epoch 110/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5947 - accuracy: 0.7045\n",
      "Epoch 111/150\n",
      "62/62 [==============================] - 0s 933us/step - loss: 0.4942 - accuracy: 0.7628\n",
      "Epoch 112/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5190 - accuracy: 0.7731\n",
      "Epoch 113/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5879 - accuracy: 0.7138\n",
      "Epoch 114/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5204 - accuracy: 0.7444\n",
      "Epoch 115/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5321 - accuracy: 0.7546\n",
      "Epoch 116/150\n",
      "62/62 [==============================] - 0s 935us/step - loss: 0.5268 - accuracy: 0.7684\n",
      "Epoch 117/150\n",
      "62/62 [==============================] - 0s 982us/step - loss: 0.4760 - accuracy: 0.7817\n",
      "Epoch 118/150\n",
      "62/62 [==============================] - 0s 990us/step - loss: 0.5671 - accuracy: 0.7300\n",
      "Epoch 119/150\n",
      "62/62 [==============================] - 0s 945us/step - loss: 0.5406 - accuracy: 0.7351\n",
      "Epoch 120/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5461 - accuracy: 0.7362\n",
      "Epoch 121/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5114 - accuracy: 0.7752\n",
      "Epoch 122/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5047 - accuracy: 0.7530\n",
      "Epoch 123/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5279 - accuracy: 0.7615\n",
      "Epoch 124/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7457: 0s - loss: 0.5494 - accuracy: 0.\n",
      "Epoch 125/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5222 - accuracy: 0.7369\n",
      "Epoch 126/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5082 - accuracy: 0.7728\n",
      "Epoch 127/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5341 - accuracy: 0.7285\n",
      "Epoch 128/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5089 - accuracy: 0.7712\n",
      "Epoch 129/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4981 - accuracy: 0.7741\n",
      "Epoch 130/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5313 - accuracy: 0.7540\n",
      "Epoch 131/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5360 - accuracy: 0.7309\n",
      "Epoch 132/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5348 - accuracy: 0.7355\n",
      "Epoch 133/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5184 - accuracy: 0.7391\n",
      "Epoch 134/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5192 - accuracy: 0.7405\n",
      "Epoch 135/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5113 - accuracy: 0.7544\n",
      "Epoch 136/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5421 - accuracy: 0.7440\n",
      "Epoch 137/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5334 - accuracy: 0.7324\n",
      "Epoch 138/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.7681\n",
      "Epoch 139/150\n",
      "62/62 [==============================] - 0s 862us/step - loss: 0.5357 - accuracy: 0.7431\n",
      "Epoch 140/150\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.5534 - accuracy: 0.73 - 0s 936us/step - loss: 0.5496 - accuracy: 0.7347\n",
      "Epoch 141/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.7741\n",
      "Epoch 142/150\n",
      "62/62 [==============================] - 0s 997us/step - loss: 0.5215 - accuracy: 0.7403\n",
      "Epoch 143/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5270 - accuracy: 0.7360: 0s - loss: 0.5269 - accuracy: 0.73\n",
      "Epoch 144/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5192 - accuracy: 0.7395\n",
      "Epoch 145/150\n",
      "62/62 [==============================] - 0s 997us/step - loss: 0.4966 - accuracy: 0.7309\n",
      "Epoch 146/150\n",
      "62/62 [==============================] - 0s 986us/step - loss: 0.4793 - accuracy: 0.7789\n",
      "Epoch 147/150\n",
      "62/62 [==============================] - 0s 946us/step - loss: 0.4934 - accuracy: 0.7570\n",
      "Epoch 148/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5318 - accuracy: 0.7416\n",
      "Epoch 149/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4737 - accuracy: 0.7770\n",
      "Epoch 150/150\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.5149 - accuracy: 0.7536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x282d4e0f850>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting model\n",
    "kerasmodel.fit(X_train, y_train, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "066eceaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 756us/step - loss: 0.5808 - accuracy: 0.7231\n",
      "Train Accuracy: 72.31\n"
     ]
    }
   ],
   "source": [
    "# Train accuracy\n",
    "_, accuracy = kerasmodel.evaluate(X_train, y_train)\n",
    "print('Train Accuracy: %.2f' %(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54fc0b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test results\n",
    "y_pred = kerasmodel.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f932a6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0804cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c363cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[94,  3],\n",
       "       [49,  8]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70d7142c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1af1b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6623376623376623"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bb8565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
